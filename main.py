import tkinter as tk
from tkinter import filedialog
from PIL import Image, ImageTk
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.densenet import DenseNet201, preprocess_input
import pickle
from googletrans import Translator  # Ù„Ø§Ø²Ù… ØªÙƒÙˆÙ† Ù…Ø«Ø¨Øª Ù…ÙƒØªØ¨Ø© googletrans==4.0.0-rc1

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„ØªÙˆÙƒÙ†Ø§ÙŠØ²Ø± ÙˆØ§Ù„ÙÙŠØªØ´Ø±Ø²
model = load_model('trained_caption__Transformer_model.h5')  
tokenizer = pickle.load(open('tokenizer.pkl', 'rb'))  
all_features = pickle.load(open('features.pkl', 'rb'))  
max_length = 35  # Ø¹Ø¯Ù„ Ø­Ø³Ø¨ Ù…Ø´Ø±ÙˆØ¹Ùƒ

# ØªØ­Ù…ÙŠÙ„ DenseNet201 Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª
feature_extractor = DenseNet201(weights='imagenet', include_top=False, pooling='avg')

# Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙÙŠØªØ´Ø± Ù„ØµÙˆØ±Ø© Ø¬Ø¯ÙŠØ¯Ø©
def extract_features_new_image(img_path):
    img = image.load_img(img_path, target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)

    features = feature_extractor.predict(img_array)
    features = np.reshape(features, features.shape[1])
    return features
# Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ÙƒØ§Ø¨Ø´Ù†
def predict_caption(model, tokenizer, photo, max_length):
    in_text = 'startseq'
    for i in range(max_length):
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        sequence = np.pad(sequence, (0, max_length-len(sequence)), 'constant')
        sequence = np.expand_dims(sequence, axis=0)
        yhat = model.predict([np.expand_dims(photo, axis=0), sequence], verbose=0)
        yhat = np.argmax(yhat)
        word = tokenizer.index_word.get(yhat)
        if word is None:
            break
        in_text += ' ' + word
        if word == 'endseq':
            break
    return in_text
# Ø¯Ø§Ù„Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒØ§Ø¨Ø´Ù† Ù„Ù„ØµÙˆØ±Ø©
def generate_caption(image_path):
    image_name = image_path.split("/")[-1]  # Ù„Ùˆ Ø¹Ù„Ù‰ ÙˆÙŠÙ†Ø¯ÙˆØ² Ù…Ù…ÙƒÙ† ØªØ­ØªØ§Ø¬ "\\" Ø¨Ø¯Ù„ "/"
    if image_name in all_features:
        features = all_features[image_name]
        if len(features.shape) > 1:
            features = np.reshape(features, (features.shape[1],))  # Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ÙƒÙŠÙ„ Ø§Ù„ÙÙŠØªØ´Ø± Ø¥Ù„Ù‰ Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„ØµØ­ÙŠØ­
    else:
        features = extract_features_new_image(image_path)

    caption = predict_caption(model, tokenizer, features, max_length)
    return caption
# Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Google Translate
def translate_to_arabic(text):
    translator = Translator()
    translated = translator.translate(text, src='en', dest='ar')
    return translated.text

# Ø¯Ø§Ù„Ø© ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø© ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
def open_image():
    file_path = filedialog.askopenfilename()
    if file_path:
        img = Image.open(file_path)
        img = img.resize((300, 300))
        img = ImageTk.PhotoImage(img)
        panel.configure(image=img)
        panel.image = img

        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒØ§Ø¨Ø´Ù†
        caption = generate_caption(file_path)
        caption_clean = caption.replace('startseq', '').replace('endseq', '').strip()
          # Ø­Ø°Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ØªÙƒØ±Ø±Ø© Ø§Ù„Ù…ØªØªØ§Ù„ÙŠØ©
        words = caption_clean.split()
        cleaned_words = [words[0]] + [words[i] for i in range(1, len(words)) if words[i] != words[i-1]]
        caption_clean = ' '.join(cleaned_words)

        # ØªØ±Ø¬Ù…Ø© Ø§Ù„ÙƒØ§Ø¨Ø´Ù†
        translated_caption = translate_to_arabic(caption_clean)

        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        caption_label.config(text=f"ğŸ“ Caption: {caption_clean}")
        translation_label.config(text=f"ğŸŒ ØªØ±Ø¬Ù…Ø©: {translated_caption}")

# Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø§ÙØ°Ø©
root = tk.Tk()
root.title("Image Caption Generator & Translator")
root.configure(bg="#F7F7F7")

# Ø²Ø±Ø§Ø± Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ØµÙˆØ±Ø©
btn = tk.Button(root, text="ğŸ“· Ø§Ø®ØªØ± ØµÙˆØ±Ø©", command=open_image, bg="green", fg="white", font=("Helvetica", 16))
btn.pack(pady=10)
# Ù…ÙƒØ§Ù† Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø©
panel = tk.Label(root)
panel.pack(pady=10)

# Ù…ÙƒØ§Ù† Ø¹Ø±Ø¶ Ø§Ù„ÙƒØ§Ø¨Ø´Ù†
caption_label = tk.Label(root, text="", bg="#F7F7F7", font=("Helvetica", 14), wraplength=500, justify="center")
caption_label.pack(pady=10)

# Ù…ÙƒØ§Ù† Ø¹Ø±Ø¶ Ø§Ù„ØªØ±Ø¬Ù…Ø©
translation_label = tk.Label(root, text="", bg="#F7F7F7", font=("Helvetica", 14), fg="green", wraplength=500, justify="center")
translation_label.pack(pady=10)

root.mainloop()
